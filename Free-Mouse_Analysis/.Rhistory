dev.off()
}
library(lme4)
library(lmerTest)
library(brms)
library(parameters)
library(tidyverse)
library(beanplot)
library(sjstats)
library(optimx)
library(HLMdiag)
library(DHARMa)
library(sjPlot)
library(effects)
library(grid)
library(gridExtra)
library(ggplot2)
library(broom.mixed)
library(ggeffects)
library(caret)
library(Hmisc)
library(merTools)
# get the current working directory (all plots and data are saved in the current working directory!)
wd <- getwd()
setwd("C:/Users/Paul/Desktop/Data_Analysis/Free-Mouse_Analysis")
# load the dataset
# Note that R automatically adds an X before the numbers in the column names,
# e.g. column name: 3000_recording_duration -> X3000_recording_duration
mouse_data <- read.csv(file = 'Free_Mouse_Features.csv')
# get some bacic stats about the dataset
# Number of rows and columns
dim(mouse_data)
# number of unique participants
length(table(mouse_data$ID))
# and their sorted number of measurements
sort(table(mouse_data$ID))
# list of dependent variables that will be analysed
dvs <- c("arousal", "valence")
# list of predictors (dependent variables) that will (potentially) be analysed
ivs <- c(
'recording_duration', 'movement_episodes', 'mo_ep_mean_episode_duration',
'mo_ep_sd_episode_duration', 'mo_ep_mean_total_dist', 'mo_ep_sd_total_dist',
'mo_ep_mean_speed_mean', 'mo_ep_sd_speed_mean', 'mo_ep_mean_speed_sd', 'mo_ep_sd_speed_sd',
'mo_ep_mean_abs_accel_mean', 'mo_ep_sd_abs_accel_mean', 'mo_ep_mean_abs_accel_sd',
'mo_ep_sd_abs_accel_sd', 'mo_ep_mean_abs_jerk_mean', 'mo_ep_sd_abs_jerk_mean',
'mo_ep_mean_abs_jerk_sd', 'mo_ep_sd_abs_jerk_sd', 'mo_ep_mean_angle_mean',
'mo_ep_sd_angle_mean', 'mo_ep_mean_angle_sd', 'mo_ep_sd_angle_sd', 'mo_ep_mean_x_flips',
'mo_ep_sd_x_flips', 'mo_ep_mean_y_flips', 'mo_ep_sd_y_flips', 'movement_duration',
'movement_distance', 'no_movement', 'lockscreen_episodes.', "lockscreen_time"
)
length(ivs)
# function to perform the rank-based inverse normal transformation for the
# mouse usage features and target variable following the formular of
# Bishara, A. J., & Hittner, J. B. (2012). Testing the significance of a correlation
# with nonnormal data: comparison of Pearson, Spearman, transformation, and
# resampling approaches. Psychological Methods, 17(3), 399-417.
# https://doi.org/10.1037/a0028087
rank_based_inverse_normal_transform <- function(x)
{
qnorm((rank(x, na.last = "keep") - 0.5) / sum(!is.na(x)))
}
# initialize the dataset list that will iterated in the data analysis step
dataset_list <- list()
# create a preprocessed dataset for every pause threshold
pause_thresholds <- c("1000", "2000", "3000")
# loop the pause thresholds
for (option in pause_thresholds) {
# get the raw data set
data_to_transform <- mouse_data
print(paste0("Creating Dataset for pause threshold ", option, "ms"))
# select the relevant ivs for the specified pause threshold (add the pause threshold and X to the name, if it exists
# in the column names vector of the dataframe (the lockscreen time variables have no pause threshold prefix)
sel_ivs <- ifelse(is.element(paste0('X', option, "_", ivs), colnames(data_to_transform)),
paste0('X', option, "_", ivs), ivs)
# create the relevant dataset (most of the following code could be done in one pipeline. I prefer to separate it
# for better readability of the steps. This preference likely is not very R-like)
# Step 1: select the relevant iv columns based on the pause threshold and get rid of all other pause threshold ivs
data_to_transform <- data_to_transform %>%
# rename the selected columns to the iv names
rename_with(~ ivs[which(sel_ivs == .x)], .cols = sel_ivs) %>%
# filter out all non selected/renamed iv columns
dplyr::select(!matches("1000|2000|3000"))
# Step 2: Remove highly correlated features from the dataset
corr_table <- data_to_transform %>% select(all_of(ivs)) %>% cor(.)
# find the index of all bivariate correlations above the specified threshold using the caret::findCorrelation func
# https://www.rdocumentation.org/packages/caret/versions/6.0-90/topics/findCorrelation
index <- caret::findCorrelation(corr_table, .80, exact = FALSE)
# get the names of the columns that will be removed
to_be_removed <- colnames(corr_table)[index]
# remove the columns from the dataframe
data_to_transform <- data_to_transform %>%  select(-all_of(to_be_removed))
# get the remaining predictors
remaining_predictors <- ivs[ivs %in% colnames(data_to_transform)]
# Step 3: Transform the IV and DV using rank-based inverse normal transformation
data_to_transform <- data_to_transform %>%
mutate(across(.cols = all_of(c(remaining_predictors, dvs)), rank_based_inverse_normal_transform))
# Step 4: For every predictor, separate the predictor into its state and trait
# component -> the trait is the person mean of the predictor and the state
# is the person mean centered predictor variable
data_to_transform <- data_to_transform %>%
add_column(demean(., select = c(remaining_predictors), group = "ID"))
# Step 5: add the transformed dataset to the list of all datasets
dataset_list[[option]] <- data_to_transform
}
# load the dataset
# Note that R automatically adds an X before the numbers in the column names,
# e.g. column name: 3000_recording_duration -> X3000_recording_duration
mouse_data <- read.csv(file = 'Free_Mouse_Features.csv')
# get some bacic stats about the dataset
# Number of rows and columns
dim(mouse_data)
# number of unique participants
length(table(mouse_data$ID))
# and their sorted number of measurements
sort(table(mouse_data$ID))
# list of dependent variables that will be analysed
dvs <- c("arousal", "valence")
# list of predictors (dependent variables) that will (potentially) be analysed
ivs <- c(
'recording_duration', 'movement_episodes', 'mo_ep_mean_episode_duration',
'mo_ep_sd_episode_duration', 'mo_ep_mean_total_dist', 'mo_ep_sd_total_dist',
'mo_ep_mean_speed_mean', 'mo_ep_sd_speed_mean', 'mo_ep_mean_speed_sd', 'mo_ep_sd_speed_sd',
'mo_ep_mean_abs_accel_mean', 'mo_ep_sd_abs_accel_mean', 'mo_ep_mean_abs_accel_sd',
'mo_ep_sd_abs_accel_sd', 'mo_ep_mean_abs_jerk_mean', 'mo_ep_sd_abs_jerk_mean',
'mo_ep_mean_abs_jerk_sd', 'mo_ep_sd_abs_jerk_sd', 'mo_ep_mean_angle_mean',
'mo_ep_sd_angle_mean', 'mo_ep_mean_angle_sd', 'mo_ep_sd_angle_sd', 'mo_ep_mean_x_flips',
'mo_ep_sd_x_flips', 'mo_ep_mean_y_flips', 'mo_ep_sd_y_flips', 'movement_duration',
'movement_distance', 'no_movement', 'lockscreen_episodes.', "lockscreen_time"
)
length(ivs)
# function to perform the rank-based inverse normal transformation for the
# mouse usage features and target variable following the formular of
# Bishara, A. J., & Hittner, J. B. (2012). Testing the significance of a correlation
# with nonnormal data: comparison of Pearson, Spearman, transformation, and
# resampling approaches. Psychological Methods, 17(3), 399-417.
# https://doi.org/10.1037/a0028087
rank_based_inverse_normal_transform <- function(x)
{
qnorm((rank(x, na.last = "keep") - 0.5) / sum(!is.na(x)))
}
# initialize the dataset list that will iterated in the data analysis step
dataset_list <- list()
# create a preprocessed dataset for every pause threshold
pause_thresholds <- c("1000", "2000", "3000")
# loop the pause thresholds
for (option in pause_thresholds) {
# get the raw data set
data_to_transform <- mouse_data
print(paste0("Creating Dataset for pause threshold ", option, "ms"))
# select the relevant ivs for the specified pause threshold (add the pause threshold and X to the name, if it exists
# in the column names vector of the dataframe (the lockscreen time variables have no pause threshold prefix)
sel_ivs <- ifelse(is.element(paste0('X', option, "_", ivs), colnames(data_to_transform)),
paste0('X', option, "_", ivs), ivs)
# create the relevant dataset (most of the following code could be done in one pipeline. I prefer to separate it
# for better readability of the steps. This preference likely is not very R-like)
# Step 1: select the relevant iv columns based on the pause threshold and get rid of all other pause threshold ivs
data_to_transform <- data_to_transform %>%
# rename the selected columns to the iv names
rename_with(~ ivs[which(sel_ivs == .x)], .cols = sel_ivs) %>%
# filter out all non selected/renamed iv columns
dplyr::select(!matches("1000|2000|3000"))
# Step 2: Remove highly correlated features from the dataset
corr_table <- data_to_transform %>% dplyr::select(all_of(ivs)) %>% cor(.)
# find the index of all bivariate correlations above the specified threshold using the caret::findCorrelation func
# https://www.rdocumentation.org/packages/caret/versions/6.0-90/topics/findCorrelation
index <- caret::findCorrelation(corr_table, .80, exact = FALSE)
# get the names of the columns that will be removed
to_be_removed <- colnames(corr_table)[index]
# remove the columns from the dataframe
data_to_transform <- data_to_transform %>%  dplyr::select(-all_of(to_be_removed))
# get the remaining predictors
remaining_predictors <- ivs[ivs %in% colnames(data_to_transform)]
# Step 3: Transform the IV and DV using rank-based inverse normal transformation
data_to_transform <- data_to_transform %>%
mutate(across(.cols = all_of(c(remaining_predictors, dvs)), rank_based_inverse_normal_transform))
# Step 4: For every predictor, separate the predictor into its state and trait
# component -> the trait is the person mean of the predictor and the state
# is the person mean centered predictor variable
data_to_transform <- data_to_transform %>%
add_column(demean(., select = c(remaining_predictors), group = "ID"))
# Step 5: add the transformed dataset to the list of all datasets
dataset_list[[option]] <- data_to_transform
}
# function to create and save mixed model diagnostic plots
model_diagnostic_plots <- function (model, filename, data) {
# create a PDF that has both diagnostic visualization plots on a seperate page
# the PDFs are saved in the current working directory
pdf(paste0('FreeMouse_',filename,".pdf"),
width = 10, height = 8,
bg = "white",
colormodel = "cmyk",
paper = "a4r")
# model diagnostics visualization
diagnostic_plots.1 <- DHARMa::simulateResiduals(fittedModel = model, plot = F)
diagnostic_plots.2 <- sjPlot::plot_model(model, type='diag')
# save the first plot
plot(diagnostic_plots.1)
# save the second plot
grid.arrange(diagnostic_plots.2[[1]], diagnostic_plots.2[[2]]$ID, diagnostic_plots.2[[3]], diagnostic_plots.2[[4]], nrow = 2)
dev.off()
}
# function to create and save plots about the relationship between a single predictor variable and the target
# and taking the multilevel structure into account
# all Plots are marginal effect plot of the predictor variable on the target variable controlling for the covariates
plot_single_pred_mixed_model <- function (dataset, predictor, target) {
print("Plotting the Invididual Linear Models")
# First, plot the relationship between predictor and target when ignoring the group structure plus individual
# relationship plots per participant (individual regression models)
# calculate the marginal effects between target and predictor per participant
marg_effect_predictions <- dataset%>%
group_by(ID) %>%
do(preds = ggpredict(glm(data = ., formula = as.formula(paste0(target, " ~ ", predictor)),
family = "gaussian"), terms = predictor))
# create a single dataset for plotting from the predicted marginal effects per group and add a group label
merged_marg_eff_preds <- bind_rows(marg_effect_predictions$preds, .id = "par")
# plot the invididual regression lines
lm_plot <- ggplot(data = merged_marg_eff_preds, aes(x = x, y = predicted, colour = par)) +
# add participant regression line
geom_line(size = 1, alpha = 0.5) +
# add the regression line of the total dataset when ignoring the grouped data structure
geom_line(data = ggpredict(glm(formula = as.formula(paste(target, " ~ ", predictor)),
data = dataset, family = "gaussian"), terms = predictor),
aes(x = x, y = predicted), colour = "black", size = 2) +
# add the conf intervals of the regression line
geom_ribbon(data = ggpredict(glm(formula = as.formula(paste(target, " ~ ", predictor)),
data = dataset, family = "gaussian"), terms = predictor),
aes(x = x, y = predicted, ymin = conf.low, ymax = conf.high, colour = NULL), alpha =0.2) +
theme_light() +
xlab(predictor) + ylab(target) +
labs(title = paste0(target, " by ", predictor),
subtitle = "Model per Group and Overall") +
theme(legend.position="none")
# Second, Plot the random intercept model with individual slopes per participant + the general slope of the random
# intercept model
print("Plotting the Fixed Effect Mixed Model")
# calculate the fixed effect model first
fe_formular <- paste(target, '~', paste0(predictor, "_within"), '+',paste0(predictor, "_between"), '+ (1|ID)')
fixed_effect_model <- lmer(formula = as.formula(fe_formular), data = dataset, REML = F, control=lmerControl(optimizer = "bobyqa"))
# now plot it
ri_plot <- ggplot(data = ggpredict(fixed_effect_model, terms = c(paste0(predictor, "_within"))), aes(x = x, y = predicted)) +
# linear model for each participant with unique intercept
geom_line(data = ggpredict(fixed_effect_model, terms = c(paste0(predictor, "_within"), "ID"), type = "re"),
aes(x = x, y = predicted, colour = group),
size = 1, alpha = 0.5) +
# general trend of the random intercept model
geom_line(colour = "black", size = 2) +
geom_ribbon(aes(ymin = conf.low, ymax = conf.high), alpha =0.2) +
theme_light() +
xlab(predictor) + ylab(target) +
labs(title = paste0(target, " by ", predictor),
subtitle = "Random Intercept Model") +
theme(legend.position="none")
# Third, Plot the random intercept and random slopes model + the general slope of the random intercept + slope model
print("Plotting the Random Slope Mixed Model")
# calculate the random slope model first
re_formular <- paste(target, '~', paste0(predictor, "_within"), '+',paste0(predictor, "_between"), '+ (', paste0(predictor, "_within"), '|ID)')
random_effect_model <- lmer(formula = as.formula(re_formular), data = dataset, REML = F, control=lmerControl(optimizer = "bobyqa"))
# now plot it
rs_plot <- ggplot(data = ggpredict(random_effect_model, terms = c(paste0(predictor, "_within"))), aes(x = x, y = predicted)) +
# linear relationships for each participant
geom_line(data = ggpredict(random_effect_model, terms = c(paste0(predictor, "_within"), "ID"), type = "re"),
aes(x = x, y = predicted, colour = group),
size = 1, alpha = 0.5) +
# general trend of the random slope model
geom_line(color = "black", size = 2) +
geom_ribbon(aes(ymin = conf.low, ymax = conf.high), alpha = 0.2) +
theme_light() +
xlab(predictor) + ylab(target) +
labs(title = paste0(target, " by ", predictor),
subtitle = "Random Intercept and Slope Model") +
theme(legend.position="none")
# save the plots in a PDF file (each plot on an individual page in the file)
# different pathname depending on the model family (binomial vs. gaussian)
save_path <- paste0("FreeMouse_single_pred_", predictor, '_', target, ".pdf")
# create the pdf in which the plots are saved
pdf(save_path,
width = 10, height = 8,
bg = "white",
colormodel = "cmyk",
paper = "a4r")
# save the lm plot
plot(lm_plot)
# save the random intercept plot on a seperate page
plot(ri_plot)
# save the random intercept + slope plot on a seperate page
plot(rs_plot)
dev.off()
}
# fit the specified mixed model, get model diagnostics (if wanted) and return
# model coefficients as well as model performance criteria
fit_mixed_model <- function(dataset, model_formular, mod_name, plot_diag = F) {
# cat(sprintf("Fitting the Model: %s\n", mod_name))
# fit the model with the specified formular
mod <- lmer(formula = as.formula(model_formular), data = dataset, REML = F, control=lmerControl(optimizer="bobyqa"))
# if specified, get model diagnostic visualizations
if (plot_diag) {model_diagnostic_plots(model = mod, filename = mod_name, data = dataset) }
# grab the model coefficients
coefficients <- broom.mixed::tidy(mod, conf.int = T, conf.method = "Wald")
# calculate standardized model coefficients using the parameters package
# which implements a method from Hoffman, 2015
# get standardized model parameters
standardized_coeffs <- parameters::standardise_parameters(mod, method = "pseudo", ci_method = "Wald")
# calculate the model performance criteria
model_diag <- performance::model_performance(mod)
# calculate another RÂ² value as the squared correlation between the
# response variabe the and predicted values, which is suggested
# by Hoffman et al., 2015 and also mentioned in a blog post about mixed model
# goodness-of-fit coefficients by the author of the lme4 package
# http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#how-do-i-compute-a-coefficient-of-determination-r2-or-an-analogue-for-glmms
explained_var <- cor(model.response(model.frame(mod)),predict(mod,type="response"))^2
# add ot to the model diagnostic criteria
model_diag["pseudo_R2"] <- explained_var
# return the model, the model coefficients and the performance criteria in a list
list(mod = mod, coeffs = coefficients, std_coeffs=standardized_coeffs,
model_diag = model_diag)
}
# the mixed model functions require a dataset, a target and a predictor (or 2 for the interaction effect) and the model
# family
# Here, random inputs are selected, but this can be adapted to manually selected options
# select a random item from the list, but leave the list inplace in order to get the name of the dataset
# write a small helper function (get random items or put them in manually)
get_sample_data <- function (dset = NULL, target = NULL, predictor = NULL) {
# draw a random dataset if no dataset is specified
play_dataset <- if (!is.null(dset)) dset else dataset_list[sample(seq_along(dataset_list), 1)]
# draw a random target variable
play_target <- if (!is.null(target)) target else sample(dvs, 1)
# draw a random iv from the sample dataset
play_pred <- if (!is.null(predictor)) target else sample(ivs[ivs %in% colnames(play_dataset[[1]])], 1)
list("dset" = play_dataset, "target" = play_target, "pred" = play_pred)
}
# get a random dataset, the predictor and the target
rng_play_dat <- get_sample_data()
rng_pred <- rng_play_dat[["pred"]]
rng_target <- rng_play_dat[["target"]]
# simple helper function to save the model results as separate csv files
save_model_results <- function (model_list) {
# loop the model results list and save the results
lapply(names(model_list), function (x) write.csv(x=model_list[[x]], file = paste0(x, ".csv"), row.names = F))
}
# setup lists to store the model result of the loops
ri_coeff_list <- list()
ri_diag_list <- list()
fe_coeff_list <- list()
fe_std_coeff_list <- list()
fe_diag_list <- list()
rs_coeff_list <- list()
rs_std_coeff_list <- list()
rs_diag_list <- list()
model_comparison <- list()
mouse_icc <- list()
# loop over all dataframes
for (i in seq_along(dataset_list)) {
dset_name <- names(dataset_list[i])
dset <- dataset_list[[i]]
# loop over all dependent variables
for (dv in dvs) {
print(paste("Calculating the ICC Model for dataset", dset_name, "and target", dv))
# first calculate the random intercept model for the outcome variable
icc_model <- fit_mixed_model(dataset = dset,
model_formular = paste(dv, '~', '1 + (1|ID)'),
mod_name = paste0("NullMod_", dv, "_" , dset_name),
plot_diag = F)
# extract the results from the model, add the info about the dv and dataset
icc_coeffs <- icc_model[["coeffs"]] %>% mutate(dv = dv, dframe = dset_name)
icc_diag <- icc_model[["model_diag"]] %>% mutate(dv = dv, dframe = dset_name)
# save them in the list
ri_coeff_list[[paste0(dset_name, "_", dv)]] <- icc_coeffs
ri_diag_list[[paste0(dset_name, "_", dv)]] <- icc_diag
# next, loop all predictors and calculate the predictor models
# to do so, first get the name of the remaining predictors in the dataset
# after preprocessing
remaining_ivs <- ivs[ivs %in% colnames(dset)]
# next, loop the remaining ivs
for (iv in remaining_ivs) {
print(paste("Calculating the models predictor", iv, " in dataset", dset_name, "and target", dv))
# calculate the fixed effect model first
fe_model <- fit_mixed_model(dataset = dset,
model_formular = paste(dv, '~', paste0(iv, "_within"), "+", paste0(iv, "_between"), '+ (1|ID)'),
mod_name = paste0("FE_Mod", iv, "_", dv, "_" , dset_name),
plot_diag = F)
# calculate the random effect model second
rs_model <- fit_mixed_model(dataset = dset,
model_formular = paste(dv, '~', paste0(iv, "_within"), "+", paste0(iv, "_between"), '+ (', paste0(iv, "_within"), '|ID)'),
mod_name = paste0("RE_Mod", iv, "_", dv, "_" , dset_name),
plot_diag = F)
# Again, extract the infos from the models and save them in the lists
fe_coeffs <- fe_model[["coeffs"]] %>% mutate(iv = iv, dv = dv, dframe = dset_name)
fe_std_coeffs <- fe_model[["std_coeffs"]] %>% mutate(iv = iv, dv = dv, dframe = dset_name)
fe_diag <- fe_model[["model_diag"]] %>% mutate(iv = iv, dv = dv, dframe = dset_name)
fe_coeff_list[[paste0(iv, "_", dset_name, "_", dv)]] <- fe_coeffs
fe_std_coeff_list[[paste0(iv, "_", dset_name, "_", dv)]] <- fe_std_coeffs
fe_diag_list[[paste0(iv, "_", dset_name, "_", dv)]] <- fe_diag
rs_coeffs <- rs_model[["coeffs"]] %>% mutate(iv = iv, dv = dv, dframe = dset_name)
rs_std_coeffs <- rs_model[["std_coeffs"]] %>% mutate(iv = iv, dv = dv, dframe = dset_name)
rs_diag <- rs_model[["model_diag"]] %>% mutate(iv = iv, dv = dv, dframe = dset_name)
rs_coeff_list[[paste0(iv, "_", dset_name, "_", dv)]] <- rs_coeffs
rs_std_coeff_list[[paste0(iv, "_", dset_name, "_", dv)]] <- rs_std_coeffs
rs_diag_list[[paste0(iv, "_", dset_name, "_", dv)]] <- rs_diag
# then, compare the nested models
comparison <- performance::test_performance(icc_model[["mod"]],
fe_model[["mod"]],
rs_model[["mod"]]) %>%
mutate(iv = iv, dv = dv, dframe = dset_name)
# and add the it to the results list
model_comparison[[paste0(iv, "_", dset_name, "_", dv)]] <- comparison
# finally, also calculate the ICC for a random intercept only model with
# the mouse usage predictor as the dependent variable to check how much
# between-person variance and within-person variance the mouse usage
# features have
mouseICC <- merTools::ICC(outcome = iv, group = "ID", data = dset_name)
icc_df <- data.frame (ICC  = c(mouseICC),
iv = c(iv),
dframe = c(dset_name))
# add it to the results list
mouse_icc[[paste0(iv, "_", dset_name, "_", dv)]] <- icc_df
}
}
}
# setup lists to store the model result of the loops
ri_coeff_list <- list()
ri_diag_list <- list()
fe_coeff_list <- list()
fe_std_coeff_list <- list()
fe_diag_list <- list()
rs_coeff_list <- list()
rs_std_coeff_list <- list()
rs_diag_list <- list()
model_comparison <- list()
mouse_icc <- list()
# loop over all dataframes
for (i in seq_along(dataset_list)) {
dset_name <- names(dataset_list[i])
dset <- dataset_list[[i]]
# loop over all dependent variables
for (dv in dvs) {
print(paste("Calculating the ICC Model for dataset", dset_name, "and target", dv))
# first calculate the random intercept model for the outcome variable
icc_model <- fit_mixed_model(dataset = dset,
model_formular = paste(dv, '~', '1 + (1|ID)'),
mod_name = paste0("NullMod_", dv, "_" , dset_name),
plot_diag = F)
# extract the results from the model, add the info about the dv and dataset
icc_coeffs <- icc_model[["coeffs"]] %>% mutate(dv = dv, dframe = dset_name)
icc_diag <- icc_model[["model_diag"]] %>% mutate(dv = dv, dframe = dset_name)
# save them in the list
ri_coeff_list[[paste0(dset_name, "_", dv)]] <- icc_coeffs
ri_diag_list[[paste0(dset_name, "_", dv)]] <- icc_diag
# next, loop all predictors and calculate the predictor models
# to do so, first get the name of the remaining predictors in the dataset
# after preprocessing
remaining_ivs <- ivs[ivs %in% colnames(dset)]
# next, loop the remaining ivs
for (iv in remaining_ivs) {
print(paste("Calculating the models predictor", iv, " in dataset", dset_name, "and target", dv))
# calculate the fixed effect model first
fe_model <- fit_mixed_model(dataset = dset,
model_formular = paste(dv, '~', paste0(iv, "_within"), "+", paste0(iv, "_between"), '+ (1|ID)'),
mod_name = paste0("FE_Mod", iv, "_", dv, "_" , dset_name),
plot_diag = F)
# calculate the random effect model second
rs_model <- fit_mixed_model(dataset = dset,
model_formular = paste(dv, '~', paste0(iv, "_within"), "+", paste0(iv, "_between"), '+ (', paste0(iv, "_within"), '|ID)'),
mod_name = paste0("RE_Mod", iv, "_", dv, "_" , dset_name),
plot_diag = F)
# Again, extract the infos from the models and save them in the lists
fe_coeffs <- fe_model[["coeffs"]] %>% mutate(iv = iv, dv = dv, dframe = dset_name)
fe_std_coeffs <- fe_model[["std_coeffs"]] %>% mutate(iv = iv, dv = dv, dframe = dset_name)
fe_diag <- fe_model[["model_diag"]] %>% mutate(iv = iv, dv = dv, dframe = dset_name)
fe_coeff_list[[paste0(iv, "_", dset_name, "_", dv)]] <- fe_coeffs
fe_std_coeff_list[[paste0(iv, "_", dset_name, "_", dv)]] <- fe_std_coeffs
fe_diag_list[[paste0(iv, "_", dset_name, "_", dv)]] <- fe_diag
rs_coeffs <- rs_model[["coeffs"]] %>% mutate(iv = iv, dv = dv, dframe = dset_name)
rs_std_coeffs <- rs_model[["std_coeffs"]] %>% mutate(iv = iv, dv = dv, dframe = dset_name)
rs_diag <- rs_model[["model_diag"]] %>% mutate(iv = iv, dv = dv, dframe = dset_name)
rs_coeff_list[[paste0(iv, "_", dset_name, "_", dv)]] <- rs_coeffs
rs_std_coeff_list[[paste0(iv, "_", dset_name, "_", dv)]] <- rs_std_coeffs
rs_diag_list[[paste0(iv, "_", dset_name, "_", dv)]] <- rs_diag
# then, compare the nested models
comparison <- performance::test_performance(icc_model[["mod"]],
fe_model[["mod"]],
rs_model[["mod"]]) %>%
mutate(iv = iv, dv = dv, dframe = dset_name)
# and add the it to the results list
model_comparison[[paste0(iv, "_", dset_name, "_", dv)]] <- comparison
# finally, also calculate the ICC for a random intercept only model with
# the mouse usage predictor as the dependent variable to check how much
# between-person variance and within-person variance the mouse usage
# features have
mouseICC <- merTools::ICC(outcome = iv, group = "ID", data = dset)
icc_df <- data.frame (ICC  = c(mouseICC),
iv = c(iv),
dframe = c(dset_name))
# add it to the results list
mouse_icc[[paste0(iv, "_", dset_name, "_", dv)]] <- icc_df
}
}
}
# convert each list to a "final results" dataframe and save the final results in a list
freeMouse_results <- list("FreeMouse_results_ri_coeffs" = dplyr::bind_rows(ri_coeff_list),
"FreeMouse_results_ri_diag" = dplyr::bind_rows(ri_diag_list),
"FreeMouse_results_fe_coeffs" = dplyr::bind_rows(fe_coeff_list),
"FreeMouse_results_fe_std_coeffs" = dplyr::bind_rows(fe_std_coeff_list),
"FreeMouse_results_fe_diag" = dplyr::bind_rows(fe_diag_list),
"FreeMouse_results_rs_coeffs" = dplyr::bind_rows(rs_coeff_list),
"FreeMouse_results_rs_std_coeffs" = dplyr::bind_rows(rs_std_coeff_list),
"FreeMouse_results_rs_diag" = dplyr::bind_rows(rs_diag_list),
"FreeMouse_results_model_comparison" = dplyr::bind_rows(model_comparison),
"FreeMouse_results_MousePred_ICC" = dplyr::bind_rows(mouse_icc))
View(freeMouse_results)
View(freeMouse_results[["FreeMouse_results_fe_diag"]])
# save the results as csv files
save_model_results(freeMouse_results)
